package main

import (
	"bytes"
	"crypto/md5"
	"encoding/hex"
	"fmt"
	"go/parser"
	"go/token"
	"io/fs"
	"mime"
	"os"
	"path/filepath"
	"sort"
	"strconv"
	"strings"
	"unicode"
)

func Generate(sourceDir, outputFile string) error {
	if sourceDir == "" {
		return fmt.Errorf("source directory not specified")
	}

	absDir, err := filepath.Abs(sourceDir)
	if err != nil {
		return err
	}

	outDir := filepath.Dir(outputFile)
	absOutDir, err := filepath.Abs(outDir)
	if err != nil {
		return err
	}

	pkgName, err := detectPackageName(absOutDir)

	var allFiles []string
	var originalFiles []string

	if err := filepath.WalkDir(absDir, func(path string, d fs.DirEntry, err error) error {
		if err != nil {
			return err
		}
		if d.IsDir() {
			return nil
		}

		name := filepath.Base(path)
		if strings.HasPrefix(name, ".") || strings.HasSuffix(name, ".go") {
			return nil
		}

		rel, err := filepath.Rel(absDir, path)
		if err != nil {
			return fmt.Errorf("invalid path: %w", err)
		}
		if strings.Contains(rel, "..") {
			return fmt.Errorf("invalid path traversal: %s", rel)
		}

		rel = filepath.ToSlash(rel)
		allFiles = append(allFiles, rel)
		if !strings.HasSuffix(rel, ".gz") {
			originalFiles = append(originalFiles, rel)
		}
		return nil
	}); err != nil {
		return err
	}

	if len(allFiles) == 0 {
		return fmt.Errorf("no assets found in %s", absDir)
	}

	sort.Strings(allFiles)
	sort.Strings(originalFiles)

	assets := make(map[string]assetData, len(allFiles))
	for _, rel := range allFiles {
		absPath := filepath.Join(absDir, rel)
		content, err := os.ReadFile(absPath)
		if err != nil {
			return fmt.Errorf("read %s: %w", absPath, err)
		}
		assets[rel] = assetData{
			content: content,
			hash:    md5Hex(content),
		}
	}

	var rangeFiles []string
	for _, rel := range originalFiles {
		if isRangeSupported(rel) {
			rangeFiles = append(rangeFiles, rel)
		}
	}
	hasRangeSupport := len(rangeFiles) > 0

	gzMap := make(map[string]string, len(originalFiles))
	for _, orig := range originalFiles {
		if isRangeSupported(orig) {
			continue
		}
		if gzRel, ok := findGzippedAsset(allFiles, orig); ok && isCompressible(orig) {
			gzMap[orig] = gzRel
		}
	}
	hasGzipSupport := len(gzMap) > 0

	buf := bytes.NewBuffer(make([]byte, 0, estimatedBufferSize(assets)))
	if err := generateCode(buf, pkgName, assets, originalFiles, gzMap, hasRangeSupport, hasGzipSupport); err != nil {
		return err
	}

	if err := os.MkdirAll(filepath.Dir(outputFile), 0755); err != nil {
		return err
	}
	return os.WriteFile(outputFile, buf.Bytes(), 0644)
}

type assetData struct {
	content []byte
	hash    string
}

func generateCode(buf *bytes.Buffer, pkgName string, assets map[string]assetData, originalFiles []string, gzMap map[string]string, hasRangeSupport, hasGzipSupport bool) error {
	generateHeader(buf, pkgName, hasRangeSupport, hasGzipSupport)
	generateAssetVars(buf, assets)
	generateHashMap(buf, assets, originalFiles)
	generateHandler(buf, assets, originalFiles, gzMap, hasRangeSupport)
	if hasRangeSupport {
		generateRangeHelpers(buf)
	}
	return nil
}

func generateHeader(buf *bytes.Buffer, pkgName string, hasRangeSupport, hasGzipSupport bool) {
	buf.WriteString("// Code generated by assetsgen. DO NOT EDIT.\n\n")
	buf.WriteString(fmt.Sprintf("package %s\n\n", pkgName))

	imports := []string{"\"net/http\""}
	if hasRangeSupport || hasGzipSupport {
		imports = append(imports, "\"strings\"")
	}
	if hasRangeSupport {
		imports = append(imports, "\"strconv\"", "\"fmt\"")
	}

	buf.WriteString("import (\n")
	for _, imp := range imports {
		buf.WriteString("\t" + imp + "\n")
	}
	buf.WriteString(")\n\n")
}

func generateAssetVars(buf *bytes.Buffer, assets map[string]assetData) {
	keys := sortedKeys(assets)
	for _, rel := range keys {
		data := assets[rel]
		varNameSafe := assetVarName(rel, data.hash)
		writeByteArray(buf, varNameSafe, data.content)
		buf.WriteByte('\n')
	}
}

func generateHashMap(buf *bytes.Buffer, assets map[string]assetData, files []string) {
	buf.WriteString("var AssetsMap = map[string]string{\n")
	for _, rel := range files {
		buf.WriteString(fmt.Sprintf("\t%q: %q,\n", rel, assets[rel].hash))
	}
	buf.WriteString("}\n\n")
}

func generateHandler(buf *bytes.Buffer, assets map[string]assetData, files []string, gzMap map[string]string, hasRangeSupport bool) {
	buf.WriteString("func HandleAssets(w http.ResponseWriter, r *http.Request) bool {\n")
	buf.WriteString(`	if r.Method != http.MethodGet && r.Method != http.MethodHead {
		w.WriteHeader(http.StatusMethodNotAllowed)
		return true
	}

	path := r.URL.Path
`)

	for _, rel := range files {
		casePath := "/" + rel
		ct := contentType(rel)
		asset := assets[rel]
		hash := asset.hash
		assetVar := assetVarName(rel, hash)
		contentLen := len(asset.content)

		buf.WriteString(fmt.Sprintf("\tif path == %q {\n", casePath))
		buf.WriteString(fmt.Sprintf("\t\tif r.Header.Get(\"If-None-Match\") == \"\\\"%s\\\"\" {\n", hash))
		buf.WriteString("\t\t\tw.WriteHeader(http.StatusNotModified)\n\t\t\treturn true\n\t\t}\n")
		buf.WriteString(fmt.Sprintf("\t\tw.Header().Set(\"Content-Type\", %q)\n", ct))
		buf.WriteString("\t\tw.Header().Set(\"Cache-Control\", \"public, max-age=31536000, immutable\")\n")
		buf.WriteString(fmt.Sprintf("\t\tw.Header().Set(\"ETag\", \"\\\"%s\\\"\")\n", hash))
		buf.WriteString("\t\tw.Header().Set(\"X-Content-Type-Options\", \"nosniff\")")

		if gzRel, ok := gzMap[rel]; ok {
			gzAsset := assets[gzRel]
			gzVar := assetVarName(gzRel, gzAsset.hash)
			gzLen := len(gzAsset.content)

			buf.WriteString(`
			if strings.Contains(r.Header.Get("Accept-Encoding"), "gzip") {
				w.Header().Set("Content-Encoding", "gzip")
				w.Header().Add("Vary", "Accept-Encoding")
				w.Header().Set("Content-Length", "`)
			buf.WriteString(strconv.Itoa(gzLen))
			buf.WriteString(`")
				if r.Method != http.MethodHead {
					w.Write(`)
			buf.WriteString(gzVar)
			buf.WriteString(`)
				}
				return true
			}`)

		}

		if isRangeSupported(rel) {
			buf.WriteString(fmt.Sprintf(`
			serveContent(w, r, %s)
			return true
		}
`, assetVar))
		} else {
			buf.WriteString(`
		w.Header().Set("Content-Length", "`)
			buf.WriteString(strconv.Itoa(contentLen))
			buf.WriteString(`")
		if r.Method != http.MethodHead {
			w.Write(`)
			buf.WriteString(assetVar)
			buf.WriteString(`)
		}
		return true
	}
`)
		}
	}

	buf.WriteString(`
	return false
}
`)
}

func generateRangeHelpers(buf *bytes.Buffer) {
	buf.WriteString(`
func serveContent(w http.ResponseWriter, r *http.Request, data []byte) {
	if r.Header.Get("Range") != "" {
		serveRange(w, r, data)
		return
	}
	w.Header().Set("Content-Length", strconv.Itoa(len(data)))
	if r.Method != http.MethodHead {
		w.Write(data)
	}
}

func serveRange(w http.ResponseWriter, r *http.Request, data []byte) {
	rangeHdr := r.Header.Get("Range")
	if !strings.HasPrefix(rangeHdr, "bytes=") {
		serveContent(w, r, data)
		return
	}

	spec := strings.TrimPrefix(rangeHdr, "bytes=")
	if strings.Contains(spec, ",") {
		w.Header().Set("Content-Range", fmt.Sprintf("bytes */%d", len(data)))
		http.Error(w, "multiple ranges not supported", http.StatusRequestedRangeNotSatisfiable)
		return
	}

	parts := strings.SplitN(spec, "-", 2)
	if len(parts) != 2 {
		serveContent(w, r, data)
		return
	}

	start, end, valid := parseRange(parts, len(data))
	if !valid {
		w.Header().Set("Content-Range", fmt.Sprintf("bytes */%d", len(data)))
		http.Error(w, "invalid range", http.StatusRequestedRangeNotSatisfiable)
		return
	}

	w.Header().Set("Content-Range", fmt.Sprintf("bytes %d-%d/%d", start, end, len(data)))
	w.Header().Set("Content-Length", strconv.Itoa(end-start+1))
	w.WriteHeader(http.StatusPartialContent)
	if r.Method != http.MethodHead {
		w.Write(data[start : end+1])
	}
}

func parseRange(parts []string, size int) (start, end int, valid bool) {
	if parts[0] == "" {
		// Suffix range: -500
		n, err := strconv.Atoi(parts[1])
		if err != nil || n <= 0 || n > size {
			return 0, 0, false
		}
		start = size - n
		end = size - 1
		return start, end, true
	}

	start, err := strconv.Atoi(parts[0])
	if err != nil || start < 0 || start >= size {
		return 0, 0, false
	}

	if parts[1] == "" {
		end = size - 1
		return start, end, true
	}

	end, err = strconv.Atoi(parts[1])
	if err != nil || end < start || end >= size {
		return 0, 0, false
	}
	return start, end, true
}
`)
}

func md5Hex(data []byte) string {
	sum := md5.Sum(data)
	return hex.EncodeToString(sum[:8])
}

func assetVarName(path, hash string) string {
	base := sanitizeIdentifier(path)
	return "asset_" + base + "_" + hash
}

func sanitizeIdentifier(s string) string {
	var b strings.Builder
	b.Grow(len(s))
	for i, r := range s {
		if unicode.IsLetter(r) || (i > 0 && unicode.IsDigit(r)) {
			b.WriteRune(r)
		} else {
			b.WriteRune('_')
		}
	}
	result := b.String()
	if result == "" || unicode.IsDigit(rune(result[0])) {
		return "_" + result
	}
	return result
}

func findGzippedAsset(all []string, orig string) (string, bool) {
	target := orig + ".gz"
	for _, f := range all {
		if f == target {
			return f, true
		}
	}
	return "", false
}

func isCompressible(p string) bool {
	ext := strings.ToLower(filepath.Ext(p))
	switch ext {
	case ".css", ".js", ".json", ".html", ".htm", ".svg", ".txt", ".xml", ".map":
		return true
	default:
		return false
	}
}

func isRangeSupported(p string) bool {
	ext := strings.ToLower(filepath.Ext(p))
	switch ext {
	case ".mp4", ".webm", ".mov", ".avi", ".mp3", ".ogg", ".wav", ".pdf", ".zip", ".tar", ".gz", ".bz2", ".7z", ".mkv", ".flac", ".m4a", ".m4v":
		return true
	default:
		return false
	}
}

func contentType(p string) string {
	ct := mime.TypeByExtension(filepath.Ext(p))
	if ct == "" {
		return "application/octet-stream"
	}
	return ct
}

func detectPackageName(dir string) (string, error) {
	entries, err := os.ReadDir(dir)
	if err != nil {
		return "", err
	}

	fset := token.NewFileSet()
	for _, e := range entries {
		if e.IsDir() || !strings.HasSuffix(e.Name(), ".go") {
			continue
		}

		path := filepath.Join(dir, e.Name())
		f, err := parser.ParseFile(fset, path, nil, parser.PackageClauseOnly)
		if err == nil && f.Name != nil && f.Name.Name != "" {
			return f.Name.Name, nil
		}
	}

	return sanitizePackageName(filepath.Base(dir)), nil
}

func sanitizePackageName(name string) string {
	var b strings.Builder
	b.Grow(len(name))
	for i, r := range name {
		if unicode.IsLetter(r) || (i > 0 && unicode.IsDigit(r)) {
			b.WriteRune(unicode.ToLower(r))
		}
	}
	result := b.String()
	if result == "" {
		return "assets"
	}
	return result
}

func packageToVarName(pkg string) string {
	parts := strings.FieldsFunc(pkg, func(r rune) bool {
		return r == '_' || r == '-' || r == '.'
	})

	var b strings.Builder
	b.Grow(len(pkg))
	for _, p := range parts {
		if p == "" {
			continue
		}
		runes := []rune(p)
		runes[0] = unicode.ToUpper(runes[0])
		b.WriteString(string(runes))
	}

	result := b.String()
	if result == "" {
		return "Assets"
	}
	if unicode.IsDigit(rune(result[0])) {
		return "_" + result
	}
	return result
}

func writeByteArray(buf *bytes.Buffer, name string, data []byte) {
	buf.WriteString("var " + name + " = []byte{")
	chunkSize := 16
	for i := 0; i < len(data); i += chunkSize {
		buf.WriteString("\n\t")
		end := i + chunkSize
		if end > len(data) {
			end = len(data)
		}
		for j := i; j < end; j++ {
			fmt.Fprintf(buf, "0x%02x,", data[j])
		}
	}
	buf.WriteString("\n}")
}

func sortedKeys(m map[string]assetData) []string {
	keys := make([]string, 0, len(m))
	for k := range m {
		keys = append(keys, k)
	}
	sort.Strings(keys)
	return keys
}

func estimatedBufferSize(assets map[string]assetData) int {
	size := len(assets) * 100
	for _, a := range assets {
		size += len(a.content) * 2
	}
	return size
}
